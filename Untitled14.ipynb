{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics gradio"
      ],
      "metadata": {
        "id": "tXTrVqA2m_WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from ultralytics import SAM\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", \"UsingGradioCache\")"
      ],
      "metadata": {
        "id": "nyQnj6nIm7ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚è≥ Loading SAM model...\")\n",
        "start_load = time.time()\n",
        "model = SAM(\"sam_b.pt\")\n",
        "global_load_time = time.time() - start_load\n",
        "print(f\"‚úÖ Model loaded in {global_load_time:.2f}s\")"
      ],
      "metadata": {
        "id": "FKJA0qZrE1Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_isolated_image(image, mask):\n",
        "    rgba_image = cv2.cvtColor(image, cv2.COLOR_RGB2RGBA)\n",
        "    rgba_image[:, :, 3] = 0\n",
        "    rgba_image[mask, 3] = 255\n",
        "    return rgba_image"
      ],
      "metadata": {
        "id": "enOogUBBBOkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_overlay(image, mask_tensor, color=[0, 255, 0], alpha=0.5):\n",
        "    if image.shape[2] == 3:\n",
        "        image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    else:\n",
        "        image_bgr = image.copy()\n",
        "\n",
        "    mask_np = mask_tensor.cpu().numpy().astype(np.uint8) * 255\n",
        "\n",
        "    colored_mask = np.zeros_like(image_bgr, dtype=np.uint8)\n",
        "    colored_mask[mask_np > 0] = color\n",
        "\n",
        "    overlay = cv2.addWeighted(colored_mask, alpha, image_bgr, 1 - alpha, 0)\n",
        "\n",
        "    overlay_rgb = cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return overlay_rgb"
      ],
      "metadata": {
        "id": "mxebr6dh6hhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_with_point(original_image, evt: gr.SelectData):\n",
        "    point = [evt.index[0], evt.index[1]]\n",
        "\n",
        "    print(f\"\\n‚è≥ Segmenting at point: {point}\")\n",
        "\n",
        "    start_inference = time.time()\n",
        "\n",
        "    results = model(original_image, points=point, labels=[1])\n",
        "\n",
        "    inference_time = time.time() - start_inference\n",
        "    print(f\"‚úÖ Inference complete in {inference_time:.2f}s\")\n",
        "\n",
        "    if not results or not results[0].masks:\n",
        "        print(\"‚ö†Ô∏è No objects found at this point.\")\n",
        "        perf_string = (\n",
        "            f\"Model Load: {global_load_time:.2f}s\\n\"\n",
        "            f\"Inference: {inference_time:.2f}s\\n\"\n",
        "            \"Status: No object found.\"\n",
        "        )\n",
        "        return original_image, perf_string\n",
        "\n",
        "    best_mask = results[0].masks.data[0]\n",
        "\n",
        "    annotated_image = create_overlay(original_image, best_mask, color=[0, 255, 0], alpha=0.6)\n",
        "\n",
        "    click_point_cv2 = (point[0], point[1])\n",
        "    cv2.circle(annotated_image, click_point_cv2, radius=8, color=(255, 0, 0), thickness=-1, lineType=cv2.LINE_AA)\n",
        "    cv2.circle(annotated_image, click_point_cv2, radius=10, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
        "    isolated_object = create_isolated_image(original_image, best_mask)\n",
        "    perf_string = (\n",
        "        f\"Model Load Time: {global_load_time:.2f}s\\n\"\n",
        "        f\"Inference Time: {inference_time:.2f}s\\n\"\n",
        "        f\"Point Prompt: {point}\"\n",
        "    )\n",
        "\n",
        "    return annotated_image,isolated_object, perf_string"
      ],
      "metadata": {
        "id": "ZaAjxWohjEys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_to_ui(image_upload):\n",
        "    print(f\"\\nüñºÔ∏è New image uploaded. Shape: {image_upload.shape}\")\n",
        "    return image_upload, image_upload,None,None"
      ],
      "metadata": {
        "id": "n4zibgaki7GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIcZDsmIhlQh"
      },
      "outputs": [],
      "source": [
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üöÄ Interactive Segment Anything Model (SAM) Demo\n",
        "\n",
        "        This app uses the `ultralytics` library to run **SAM (sam_b.pt)**.\n",
        "\n",
        "        ### How to Use:\n",
        "        1.  Upload an image using the panel on the left.\n",
        "        2.  The image will appear on the right. **Click on any object** in the right-hand panel.\n",
        "        3.  The model will generate a segmentation mask for the object you clicked!\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    image_state = gr.State()\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            image_upload = gr.Image(type=\"numpy\", label=\"1. Upload Image\", sources=['upload', 'clipboard'])\n",
        "            performance_text = gr.Textbox(label=\"üìä Performance & Stats\", lines=4, interactive=False)\n",
        "\n",
        "            image_isolated = gr.Image(type=\"numpy\", label=\"3. Isolated Object (PNG)\", format=\"png\")\n",
        "            gr.Markdown(\"*(Right-click or long-press to save the transparent PNG)*\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            image_output = gr.Image(type=\"numpy\", label=\"2. Click on an Object to Segment\")\n",
        "\n",
        "    image_upload.upload(\n",
        "        fn=load_image_to_ui,\n",
        "        inputs=[image_upload],\n",
        "        outputs=[image_output, image_state, image_isolated, performance_text] # Clear all outputs\n",
        "    )\n",
        "\n",
        "    image_output.select(\n",
        "        fn=segment_with_point,\n",
        "        inputs=[image_state], # Use the original, clean image for segmentation\n",
        "        outputs=[image_output, image_isolated, performance_text] # Update all outputs\n",
        "    )\n",
        "demo.launch(debug=True, share=True)"
      ]
    }
  ]
}